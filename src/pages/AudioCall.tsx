import { useState, useEffect, useRef } from "react";
import { Button } from "@/components/ui/button";
import { Card } from "@/components/ui/card";
import { Phone, PhoneOff, Mic, MicOff, Volume2, VolumeX, Music } from "lucide-react";
import Navigation from "@/components/Navigation";
import { userApi, audioCallApi, memoryApi, subscriptionApi } from "@/services/api";
import { useAuth } from "@/contexts/AuthContext";
import { psychologistAI, type ChatMessage } from "@/services/openai";

const AudioCall = () => {
  const { user: authUser } = useAuth();
  const [isCallActive, setIsCallActive] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [isSpeakerOn, setIsSpeakerOn] = useState(true);
  const [callDuration, setCallDuration] = useState(0);
  const [user, setUser] = useState<any | null>(null);
  const [currentCallId, setCurrentCallId] = useState<string | null>(null);
  const [transcriptionStatus, setTranscriptionStatus] = useState<string | null>(null);
  const [audioError, setAudioError] = useState<string | null>(null);
  const [loading, setLoading] = useState(true);
  const [subscriptionInfo, setSubscriptionInfo] = useState<{ plan: 'premium' | 'free' | 'none'; remaining: number; limit: number; status: 'active' | 'inactive' | 'cancelled' | 'none' } | null>(null);
  const [isMusicOn, setIsMusicOn] = useState(false); // –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ñ–æ–Ω–æ–≤–æ–π –º—É–∑—ã–∫–æ–π
  const [isVideoPlaying, setIsVideoPlaying] = useState(false); // –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∏–¥–µ–æ –ú–∞—Ä–∫–∞

  const audioStreamRef = useRef<MediaStream | null>(null);
  const callTimerRef = useRef<number | null>(null);
  const recognitionRef = useRef<any>(null);
  const recognitionActiveRef = useRef(false);
  const isMutedRef = useRef(false);
  const isSpeakerOnRef = useRef(true);
  const conversationRef = useRef<ChatMessage[]>([]);
  const responseQueueRef = useRef<Promise<void>>(Promise.resolve());
  const audioQueueRef = useRef<ArrayBuffer[]>([]);
  const isPlayingAudioRef = useRef(false);
  const currentSpeechSourceRef = useRef<AudioBufferSourceNode | null>(null);
  const processingSoundIntervalRef = useRef<number | null>(null);
  const generationIdRef = useRef(0); // –î–ª—è –æ—Ç–º–µ–Ω—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ—á–∏ –ø—Ä–∏ –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–∏
  const audioContextRef = useRef<AudioContext | null>(null);
  const speakerGainRef = useRef<GainNode | null>(null);
  const callLimitReachedRef = useRef(false);
  const callLimitWarningSentRef = useRef(false);
  const memoryRef = useRef<string>("");
  const pendingTranscriptRef = useRef<string>("");
  const pendingProcessTimeoutRef = useRef<number | null>(null);
  const audioAnalyserRef = useRef<AnalyserNode | null>(null);
  const volumeMonitorRef = useRef<number | null>(null);
  const backgroundMusicRef = useRef<HTMLAudioElement | null>(null);
  const musicGainRef = useRef<GainNode | null>(null);
  const videoRef = useRef<HTMLVideoElement | null>(null);

  const SESSION_DURATION_SECONDS = 30 * 60; // 30 –º–∏–Ω—É—Ç –Ω–∞ —Å–µ—Å—Å–∏—é
  const SESSION_WARNING_SECONDS = SESSION_DURATION_SECONDS - 5 * 60; // –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –∑–∞ 5 –º–∏–Ω—É—Ç
  const MAX_CALL_DURATION_SECONDS = 40 * 60; // –ê–±—Å–æ–ª—é—Ç–Ω—ã–π –º–∞–∫—Å–∏–º—É–º (–¥–ª—è –ø–æ–¥—Å—Ç—Ä–∞—Ö–æ–≤–∫–∏)
  const VOICE_DETECTION_THRESHOLD = 35; // –£–≤–µ–ª–∏—á–∏–ª–∏ –ø–æ—Ä–æ–≥ –¥–æ 35, —á—Ç–æ–±—ã TTS –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–ª–æ—Å—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –∑–≤—É–∫–æ–º

  const createAudioContext = () => {
    if (!audioContextRef.current) {
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
      audioContextRef.current = new AudioContextClass();
    }
    return audioContextRef.current;
  };

  const initializeAudioContext = async () => {
    const audioContext = createAudioContext();

    if (!speakerGainRef.current && audioContext) {
      const gainNode = audioContext.createGain();
      gainNode.gain.value = isSpeakerOnRef.current ? 1 : 0;
      gainNode.connect(audioContext.destination);
      speakerGainRef.current = gainNode;
    }

    // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö AudioContext –º–æ–∂–µ—Ç –±—ã—Ç—å suspended
    if (audioContext && audioContext.state === 'suspended') {
      console.log("[AudioCall] AudioContext is suspended, attempting to resume...");
      try {
        await audioContext.resume();
        console.log("[AudioCall] AudioContext resumed successfully");
      } catch (error) {
        console.warn("[AudioCall] Failed to resume AudioContext:", error);
      }
    }

    return audioContext;
  };

  const getAudioOutputNode = () => {
    const audioContext = createAudioContext();
    if (!audioContext) {
      return null;
    }
    if (!speakerGainRef.current) {
      const gainNode = audioContext.createGain();
      gainNode.gain.value = isSpeakerOnRef.current ? 1 : 0;
      gainNode.connect(audioContext.destination);
      speakerGainRef.current = gainNode;
    }
    return speakerGainRef.current;
  };

  const playBeepSound = async (frequency: number = 800, duration: number = 200) => {
    try {
      const audioContext = await initializeAudioContext();
      const outputNode = getAudioOutputNode();
      const oscillator = audioContext.createOscillator();
      const gainNode = audioContext.createGain();

      oscillator.connect(gainNode);
      gainNode.connect(outputNode ?? audioContext.destination);

      oscillator.frequency.setValueAtTime(frequency, audioContext.currentTime);
      oscillator.type = 'sine';

      gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
      gainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + duration / 1000);

      oscillator.start(audioContext.currentTime);
      oscillator.stop(audioContext.currentTime + duration / 1000);
    } catch (error) {
      console.warn('Could not play beep sound:', error);
    }
  };

  const startProcessingSound = () => {
    if (processingSoundIntervalRef.current) {
      clearInterval(processingSoundIntervalRef.current);
    }

    // –ü–µ—Ä–≤—ã–π —Å–∏–≥–Ω–∞–ª —Å—Ä–∞–∑—É
    playBeepSound(800, 150);

    // –ó–∞—Ç–µ–º –ø–æ–≤—Ç–æ—Ä—è—Ç—å –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã
    processingSoundIntervalRef.current = window.setInterval(() => {
      playBeepSound(800, 150);
    }, 3000);
  };

  const stopProcessingSound = () => {
    if (processingSoundIntervalRef.current) {
      clearInterval(processingSoundIntervalRef.current);
      processingSoundIntervalRef.current = null;
    }
  };

  const splitIntoSentences = (text: string): string[] => {
    return text
      .split(/(?<=[.!?])\s+/u)
      .map((sentence) => sentence.trim())
      .filter((sentence) => sentence.length > 0);
  };

  const resetAudioPlayback = () => {
    audioQueueRef.current = [];
    isPlayingAudioRef.current = false;
    if (audioContextRef.current) {
      audioContextRef.current.close().catch((error) => {
        console.warn("Error closing AudioContext:", error);
      });
      audioContextRef.current = null;
    }
    speakerGainRef.current = null;
  };

  const playQueuedAudio = async () => {
    if (!Array.isArray(audioQueueRef.current)) {
      console.error("[AudioCall] audioQueueRef.current is not an array, resetting");
      audioQueueRef.current = [];
    }

    if (isPlayingAudioRef.current) {
      return;
    }

    if (audioQueueRef.current.length === 0) {
      return;
    }

    const audioContext = await initializeAudioContext();
    if (!audioContext) {
      console.warn("[AudioCall] AudioContext unavailable.");
      audioQueueRef.current = [];
      return;
    }

    const outputNode = getAudioOutputNode();
    isPlayingAudioRef.current = true;

    // –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∏–¥–µ–æ –∫–æ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è TTS
    await playVideo();

    try {
      while (audioQueueRef.current.length > 0) {
        const buffer = audioQueueRef.current.shift();
        if (!buffer || !(buffer instanceof ArrayBuffer) || buffer.byteLength === 0) continue;

        let decoded: AudioBuffer;
        try {
          decoded = await audioContext.decodeAudioData(buffer.slice(0));
        } catch (decodeError) {
          console.error("[AudioCall] Failed to decode audio data:", decodeError);
          continue;
        }

        await new Promise<void>((resolve) => {
          const source = audioContext.createBufferSource();
          source.buffer = decoded;
          source.connect(outputNode ?? audioContext.destination);
          currentSpeechSourceRef.current = source;

          source.onended = () => {
            currentSpeechSourceRef.current = null;
            resolve();
          };

          source.start(0);
        });
      }
    } catch (error) {
      console.error("[AudioCall] Error during audio playback:", error);
      audioQueueRef.current = [];
      pauseVideo(); // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –ø—Ä–∏ –æ—à–∏–±–∫–µ
    } finally {
      isPlayingAudioRef.current = false;
      if (audioQueueRef.current.length > 0) {
        void playQueuedAudio();
      } else {
        pauseVideo(); // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∫–æ–≥–¥–∞ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞
      }
    }
  };

  const enqueueSpeechPlayback = async (text: string) => {
    console.log("[AudioCall] enqueueSpeechPlayback called with text:", text);
    const sentences = splitIntoSentences(text);
    if (sentences.length === 0) return;

    const myGenId = generationIdRef.current;

    for (const sentence of sentences) {
      if (generationIdRef.current !== myGenId) {
        console.log("[AudioCall] Generation cancelled");
        break;
      }

      try {
        const audioBuffer = await psychologistAI.synthesizeSpeech(sentence);

        if (generationIdRef.current !== myGenId) break;

        if (audioBuffer && audioBuffer.byteLength > 0) {
          audioQueueRef.current.push(audioBuffer);
          if (!isPlayingAudioRef.current) {
        void playQueuedAudio();
          }
      }
    } catch (error) {
        console.warn("[AudioCall] Failed to synthesize sentence:", sentence, error);
      }
    }
  };

  const stopAssistantSpeech = () => {
    generationIdRef.current += 1;
    audioQueueRef.current = [];
    if (currentSpeechSourceRef.current) {
      try {
        currentSpeechSourceRef.current.stop();
      } catch (error) {
        console.warn("Error stopping speech source:", error);
      }
      currentSpeechSourceRef.current.disconnect();
      currentSpeechSourceRef.current = null;
    }
    isPlayingAudioRef.current = false;
    pauseVideo(); // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ –∫–æ–≥–¥–∞ TTS –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è
  };

  const initializeBackgroundMusic = async () => {
    if (!backgroundMusicRef.current) {
      try {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–æ–∫–æ–π–Ω—É—é –º—É–∑—ã–∫—É –∏–∑ public –ø–∞–ø–∫–∏
        const musicUrl = '/de144d31b1f3b3f.mp3'; // –§–∞–π–ª –∏–∑ public –ø–∞–ø–∫–∏

        backgroundMusicRef.current = new Audio(musicUrl);
        backgroundMusicRef.current.loop = true;
        backgroundMusicRef.current.volume = 0.1; // –û—á–µ–Ω—å —Ç–∏—Ö–∞—è –º—É–∑—ã–∫–∞ (10% –≥—Ä–æ–º–∫–æ—Å—Ç–∏)

        // –ü–æ–¥–∫–ª—é—á–∞–µ–º –∫ Web Audio API –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        const audioContext = await initializeAudioContext();
        if (audioContext && backgroundMusicRef.current) {
          const source = audioContext.createMediaElementSource(backgroundMusicRef.current);
          const gainNode = audioContext.createGain();
          gainNode.gain.value = 0.05; // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ø–æ–Ω–∏–∂–µ–Ω–∏–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏

          source.connect(gainNode);
          gainNode.connect(audioContext.destination);

          musicGainRef.current = gainNode;
        }
      } catch (error) {
        console.warn('Error initializing background music:', error);
      }
    }
  };

  const playBackgroundMusic = async () => {
    if (backgroundMusicRef.current) {
      try {
        await backgroundMusicRef.current.play();
        if (musicGainRef.current) {
          musicGainRef.current.gain.setValueAtTime(0.05, musicGainRef.current.context.currentTime);
        }
      } catch (error) {
        console.warn('Error playing background music:', error);
      }
    }
  };

  const pauseBackgroundMusic = () => {
    if (backgroundMusicRef.current) {
      backgroundMusicRef.current.pause();
      if (musicGainRef.current) {
        musicGainRef.current.gain.setValueAtTime(0, musicGainRef.current.context.currentTime);
      }
    }
  };

  const toggleBackgroundMusic = async () => {
    if (!backgroundMusicRef.current) {
      await initializeBackgroundMusic();
    }

    if (isMusicOn) {
      pauseBackgroundMusic();
      setIsMusicOn(false);
    } else {
      await playBackgroundMusic();
      setIsMusicOn(true);
    }
  };

  const playVideo = async () => {
    // –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –≤–∏–¥–µ–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ TTS –∞–∫—Ç–∏–≤–µ–Ω
    if (videoRef.current && !isVideoPlaying && isPlayingAudioRef.current) {
      try {
        await videoRef.current.play();
        setIsVideoPlaying(true);
      } catch (error) {
        console.warn('Error playing video:', error);
      }
    }
  };

  const pauseVideo = () => {
    if (videoRef.current && isVideoPlaying) {
      videoRef.current.pause();
      videoRef.current.currentTime = 0; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–∞ –Ω–∞—á–∞–ª–æ
      setIsVideoPlaying(false);
    }
  };

  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∏–¥–µ–æ –≤ –ø–∞—É–∑–µ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
  useEffect(() => {
    if (videoRef.current) {
      videoRef.current.pause();
      videoRef.current.currentTime = 0;
      setIsVideoPlaying(false);
    }
  }, []);

  const startVolumeMonitoring = async (stream: MediaStream) => {
    try {
      const audioContext = await initializeAudioContext();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      audioAnalyserRef.current = analyser;

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      const checkVolume = () => {
        if (!recognitionActiveRef.current || !audioAnalyserRef.current) {
          return;
        }
        analyser.getByteFrequencyData(dataArray);
        let sum = 0;
        for (let i = 0; i < dataArray.length; i++) {
          sum += dataArray[i];
        }
        const average = sum / dataArray.length;
        
        if (average > VOICE_DETECTION_THRESHOLD && isPlayingAudioRef.current) {
          console.debug(`[AudioCall] –û–±–Ω–∞—Ä—É–∂–µ–Ω –≥–æ–ª–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–≥—Ä–æ–º–∫–æ—Å—Ç—å: ${average.toFixed(1)}), –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ú–∞—Ä–∫–∞`);
          stopAssistantSpeech();
        }

        volumeMonitorRef.current = window.requestAnimationFrame(checkVolume);
      };
      volumeMonitorRef.current = window.requestAnimationFrame(checkVolume);
    } catch (error) {
      console.warn("Error starting volume monitoring:", error);
    }
  };

  const stopVolumeMonitoring = () => {
    if (volumeMonitorRef.current) {
      cancelAnimationFrame(volumeMonitorRef.current);
      volumeMonitorRef.current = null;
    }
    if (audioAnalyserRef.current) {
      audioAnalyserRef.current.disconnect();
      audioAnalyserRef.current = null;
    }
  };

  const stopRecognition = () => {
    recognitionActiveRef.current = false;
    if (recognitionRef.current) {
      try {
        recognitionRef.current.onresult = null;
        recognitionRef.current.onerror = null;
        recognitionRef.current.onend = null;
        recognitionRef.current.stop();
      } catch (error) {
        console.warn("Error stopping speech recognition:", error);
      }
      recognitionRef.current = null;
    }
  };

  const cleanupRecording = () => {
    stopRecognition();
    stopVolumeMonitoring();
    resetAudioPlayback();
    conversationRef.current = [];
    responseQueueRef.current = Promise.resolve();
    pendingTranscriptRef.current = "";
    if (pendingProcessTimeoutRef.current) {
      window.clearTimeout(pendingProcessTimeoutRef.current);
      pendingProcessTimeoutRef.current = null;
    }

    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach((track) => track.stop());
      audioStreamRef.current = null;
    }

    setTranscriptionStatus(null);
  };

  const processRecognizedText = async (rawText: string) => {
    console.log("[AudioCall] processRecognizedText –≤—ã–∑–≤–∞–Ω–∞ —Å —Ç–µ–∫—Å—Ç–æ–º:", rawText);

    if (!user) {
      console.warn("[AudioCall] –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É");
      return;
    }

    const text = rawText.trim();
    if (!text) {
      console.info("[AudioCall] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, —Ç–∏—à–∏–Ω–∞ –∏–ª–∏ –Ω–µ—Ä–∞–∑–±–æ—Ä—á–∏–≤–∞—è —Ä–µ—á—å.");
      return;
    }

    // Capture generation ID before async ops to detect interruptions
    const startGenId = generationIdRef.current;

    console.info("[AudioCall] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:", text);
    setTranscriptionStatus("–ú–∞—Ä–∫ –æ–±–¥—É–º—ã–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç...");

    conversationRef.current.push({ role: "user", content: text });

    try {
      startProcessingSound();

      const assistantReply = await psychologistAI.getVoiceResponse(conversationRef.current, memoryRef.current, false);

      // Check if interrupted
      if (generationIdRef.current !== startGenId) {
        console.log("[AudioCall] Response generation interrupted/cancelled");
        stopProcessingSound();
        return;
      }

      conversationRef.current.push({ role: "assistant", content: assistantReply });

      stopProcessingSound();
      setTranscriptionStatus("–û–∑–≤—É—á–∏–≤–∞—é –æ—Ç–≤–µ—Ç...");

      await enqueueSpeechPlayback(assistantReply);
      setTranscriptionStatus("");
      await updateConversationMemory(text, assistantReply);
    } catch (error) {
      console.error("Error generating assistant response:", error);
      stopProcessingSound();
      setAudioError("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–∑–≤—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.");
      setTranscriptionStatus("");
    }
  };

  const flushPendingTranscript = () => {
    const text = pendingTranscriptRef.current.trim();
    pendingTranscriptRef.current = "";
    if (!text) {
      return;
    }

    stopAssistantSpeech();

    responseQueueRef.current = responseQueueRef.current
      .catch((error) => console.error("Previous voice response error:", error))
      .then(() => processRecognizedText(text));
  };

  const handleRecognizedText = (rawText: string) => {
    console.log("[AudioCall] handleRecognizedText called with:", rawText);
    const segment = rawText.trim();
    if (!segment) {
      console.log("[AudioCall] Empty segment, skipping");
      return;
    }

    console.log("[AudioCall] Stopping assistant speech before processing");
    stopAssistantSpeech();

    pendingTranscriptRef.current = [pendingTranscriptRef.current, segment].filter(Boolean).join(" ");
    console.log("[AudioCall] Updated pending transcript:", pendingTranscriptRef.current);

    if (pendingProcessTimeoutRef.current) {
      window.clearTimeout(pendingProcessTimeoutRef.current);
    }

    const timeoutDelay = 5000;
    pendingProcessTimeoutRef.current = window.setTimeout(() => {
      pendingProcessTimeoutRef.current = null;
      console.log("[AudioCall] Timeout reached (5 seconds), flushing pending transcript");
      flushPendingTranscript();
    }, timeoutDelay);
  };

  const updateConversationMemory = async (userText: string, assistantText: string) => {
    if (!user || !currentCallId) {
      return;
    }

    try {
      const updatedMemory = await memoryApi.appendMemory(
        user.id, 
        "audio", 
        currentCallId, 
        userText, 
        assistantText
      );
      memoryRef.current = updatedMemory;
      console.log("[AudioCall] Memory updated and saved to DB");
    } catch (error) {
      console.error("Error updating audio memory:", error);
    }
  };

  const getUserCredentials = () => {
    const fallbackEmail = 'user@zenmindmate.com';
    const email = authUser?.email ?? fallbackEmail;
    const name = authUser?.name ?? authUser?.email ?? '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å';
    return { email, name };
  };

  useEffect(() => {
    initializeUser();
  }, [authUser]);

  useEffect(() => {
    isMutedRef.current = isMuted;

    const stream = audioStreamRef.current;
    if (!stream) {
      if (isMuted) {
        setTranscriptionStatus("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –≤—ã–∫–ª—é—á–µ–Ω");
      }
      return;
    }

    stream.getAudioTracks().forEach((track) => {
      track.enabled = !isMuted;
    });

    if (isMuted) {
      setTranscriptionStatus("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –≤—ã–∫–ª—é—á–µ–Ω");
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (error) {
          console.warn("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:", error);
        }
      }
    } else if (recognitionActiveRef.current && recognitionRef.current) {
      setTranscriptionStatus("");
      try {
        recognitionRef.current.start();
      } catch (error) {
        if (error instanceof DOMException && error.name === "InvalidStateError") {
          return;
        }
        console.warn("–ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ–∑–æ–±–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏:", error);
      }
    }
  }, [isMuted]);

  useEffect(() => {
    isSpeakerOnRef.current = isSpeakerOn;

    if (speakerGainRef.current && audioContextRef.current) {
      const gain = speakerGainRef.current.gain;
      gain.setValueAtTime(isSpeakerOn ? 1 : 0, audioContextRef.current.currentTime ?? 0);
    }
  }, [isSpeakerOn]);

  useEffect(() => {
    return () => {
      cleanupRecording();
      stopProcessingSound();
      if (callTimerRef.current) {
        clearInterval(callTimerRef.current);
      }
      if (pendingProcessTimeoutRef.current) {
        window.clearTimeout(pendingProcessTimeoutRef.current);
        pendingProcessTimeoutRef.current = null;
      }
    };
  }, []);

  const initializeUser = async () => {
    try {
      const { email, name } = getUserCredentials();
      const userData = await userApi.getOrCreateUser(email, name);
      setUser(userData);
      const info = await subscriptionApi.getAudioSessionInfo(userData.id);
      setSubscriptionInfo(info);
    } catch (error) {
      console.error('Error initializing user:', error);
    } finally {
      setLoading(false);
    }
  };

  const startCall = async () => {
    console.log("[AudioCall] –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø—É—Å–∫ –∑–≤–æ–Ω–∫–∞...");

    if (!user || isCallActive) {
      console.log("[AudioCall] –ó–≤–æ–Ω–æ–∫ —É–∂–µ –∞–∫—Ç–∏–≤–µ–Ω –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω");
      return;
    }

    try {
      const accessCheck = await subscriptionApi.checkAudioAccess(user.id);
      console.log("[AudioCall] Access check result:", accessCheck);

      if (!accessCheck.hasAccess) {
        if (accessCheck.reason === 'no_subscription') {
          setAudioError("–£ –≤–∞—Å –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π –ø–æ–¥–ø–∏—Å–∫–∏. –û—Ñ–æ—Ä–º–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—è–º.");
        } else if (accessCheck.reason === 'no_sessions_left') {
          setAudioError("–£ –≤–∞—Å –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–∏. –û—Ñ–æ—Ä–º–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–¥–ø–∏—Å–∫—É.");
        } else {
          setAudioError("–î–æ—Å—Ç—É–ø –∫ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—è–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω.");
        }
        return;
      }

      const sessionUsed = await subscriptionApi.useAudioSession(user.id);
      if (!sessionUsed) {
        setAudioError("–ù–µ —É–¥–∞–ª–æ—Å—å –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—é. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.");
        return;
      }

      console.log("[AudioCall] Audio session activated successfully");

    } catch (error) {
      console.error("[AudioCall] Error checking access:", error);
      setAudioError("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥–æ—Å—Ç—É–ø–∞ –∫ –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—è–º.");
      return;
    }

    if (typeof navigator === "undefined" || !navigator.mediaDevices) {
      console.error("[AudioCall] –ë—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç mediaDevices");
      setAudioError("–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ.");
      return;
    }

    console.log("[AudioCall] –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É Speech Recognition...");

    try {
      setAudioError(null);
      setIsMuted(false);
      isMutedRef.current = false;
      setIsSpeakerOn(true);
      setCallDuration(0);
      callLimitReachedRef.current = false;
      callLimitWarningSentRef.current = false;
      memoryRef.current = await memoryApi.getMemory(user.id, "audio");

      const sessionInfo = await subscriptionApi.getAudioSessionInfo(user.id);
      setSubscriptionInfo(sessionInfo);

      if (sessionInfo.plan === 'premium') {
        if (sessionInfo.status !== 'active') {
          setAudioError('–í–∞—à–∞ –ø—Ä–µ–º–∏—É–º –ø–æ–¥–ø–∏—Å–∫–∞ –Ω–µ –∞–∫—Ç–∏–≤–Ω–∞. –ü—Ä–æ–¥–ª–∏—Ç–µ –ø–æ–¥–ø–∏—Å–∫—É, —á—Ç–æ–±—ã –¥–µ–ª–∞—Ç—å –∑–≤–æ–Ω–∫–∏.');
          setIsCallActive(false);
          return;
        }

        if (sessionInfo.remaining <= 0) {
          setAudioError('–õ–∏–º–∏—Ç –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–π –Ω–∞ —ç—Ç–æ—Ç –º–µ—Å—è—Ü –∏—Å—á–µ—Ä–ø–∞–Ω.');
          setIsCallActive(false);
          return;
        }
      }

      const SpeechRecognitionConstructor =
        typeof window !== "undefined"
          ? (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition
          : null;

      console.log("[AudioCall] SpeechRecognition constructor:", SpeechRecognitionConstructor);

      if (!SpeechRecognitionConstructor) {
        console.error("[AudioCall] Speech Recognition API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è");
        setAudioError("–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.");
        return;
      }

      console.log("[AudioCall] –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ —Å–µ—Å—Å–∏—é –≤ –ë–î...");

      const call = await audioCallApi.createAudioCall(user.id);
      setCurrentCallId(call.id);
      console.log("[AudioCall] –ê—É–¥–∏–æ —Å–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞, ID:", call.id);

      console.log("[AudioCall] –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É...");
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      audioStreamRef.current = stream;
      console.log("[AudioCall] –ú–∏–∫—Ä–æ—Ñ–æ–Ω –¥–æ—Å—Ç—É–ø–µ–Ω, —Å–æ–∑–¥–∞–µ–º recognition...");

      const recognition = new SpeechRecognitionConstructor();
      recognition.lang = "ru-RU";
      recognition.continuous = true;
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.onresult = (event: any) => {
        console.log("[AudioCall] Recognition result event:", event);
        for (let i = event.resultIndex; i < event.results.length; i += 1) {
          const result = event.results[i];
          const transcript = result?.[0]?.transcript ?? "";
          console.log(`[AudioCall] Result ${i}: final=${result.isFinal}, transcript="${transcript}"`);
          if (result.isFinal && transcript) {
            console.log("[AudioCall] –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –ø–µ—Ä–µ–¥–∞–µ–º –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É");
            handleRecognizedText(transcript);
          }
        }
      };

      recognition.onspeechstart = () => {
        console.log("[AudioCall] Speech started - stopping assistant speech");
        stopAssistantSpeech();
      };

      recognition.onerror = (event: any) => {
        console.error("[AudioCall] Speech recognition error:", event);
        if (event?.error === "not-allowed" || event?.error === "service-not-allowed") {
          setAudioError("–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â—ë–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±—Ä–∞—É–∑–µ—Ä–∞.");
        } else if (event?.error !== "aborted") {
          setAudioError("–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.");
        }
      };

      recognition.onend = () => {
        if (!recognitionActiveRef.current) {
          return;
        }

        if (isMutedRef.current) {
          setTranscriptionStatus("–ú–∏–∫—Ä–æ—Ñ–æ–Ω –≤—ã–∫–ª—é—á–µ–Ω");
          return;
        }

        try {
          recognition.start();
        } catch (error) {
          console.warn("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏:", error);
        }
      };

      recognitionRef.current = recognition;
      recognitionActiveRef.current = true;
      console.log("[AudioCall] Recognition —Å–æ–∑–¥–∞–Ω –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω");

      await startVolumeMonitoring(stream);
      console.log("[AudioCall] –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –∑–∞–ø—É—â–µ–Ω");

      try {
        setTimeout(() => {
          console.log("[AudioCall] –ó–∞–ø—É—Å–∫–∞–µ–º speech recognition...");
          try {
            recognition.start();
            console.log("[AudioCall] Speech recognition –∑–∞–ø—É—â–µ–Ω —É—Å–ø–µ—à–Ω–æ");
          } catch (recognitionError) {
            console.error("[AudioCall] Failed to start speech recognition:", recognitionError);
            setAudioError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.");
            stopRecognition();
            cleanupRecording();
          }
        }, 500);
      } catch (error) {
        console.error("[AudioCall] Failed to start speech recognition:", error);
        setAudioError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏.");
        stopRecognition();
        cleanupRecording();
        await audioCallApi.endAudioCall(call.id, 0);
        setCurrentCallId(null);
        return;
      }

      // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞, —á—Ç–æ–±—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–≤–æ–Ω–∫–∞ —É—Å–ø–µ–ª –æ—Ç—Ä–∏—Å–æ–≤–∞—Ç—å—Å—è
      await new Promise(resolve => setTimeout(resolve, 500));

      console.log("[AudioCall] –ü—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ...");
      const greeting = "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ. –Ø –ú–∞—Ä–∫, –ø—Å–∏—Ö–æ–ª–æ–≥. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ, —á—Ç–æ –≤–∞—Å —Å–µ–π—á–∞—Å –±–æ–ª—å—à–µ –≤—Å–µ–≥–æ –±–µ—Å–ø–æ–∫–æ–∏—Ç?";
      conversationRef.current.push({ role: "assistant", content: greeting });
      await enqueueSpeechPlayback(greeting);
      console.log("[AudioCall] –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–∏–≥—Ä–∞–Ω–æ");

      if (callTimerRef.current) {
        clearInterval(callTimerRef.current);
      }

      callTimerRef.current = window.setInterval(() => {
        setCallDuration((prev) => {
          const next = prev + 1;
          
          if (!callLimitWarningSentRef.current && next >= SESSION_WARNING_SECONDS && next < SESSION_DURATION_SECONDS) {
            callLimitWarningSentRef.current = true;
            
            responseQueueRef.current = responseQueueRef.current
              .catch((error) => console.error("Previous voice response error:", error))
              .then(async () => {
                try {
                  setTranscriptionStatus("–ú–∞—Ä–∫ –ø–æ–¥–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–∏ —Å–µ—Å—Å–∏–∏...");
                  
                  const summaryPrompt = `–£ –Ω–∞—Å –æ—Å—Ç–∞–ª–æ—Å—å –æ–∫–æ–ª–æ –ø—è—Ç–∏ –º–∏–Ω—É—Ç –¥–æ –∫–æ–Ω—Ü–∞ –Ω–∞—à–µ–π —Ç—Ä–∏–¥—Ü–∞—Ç–∏–º–∏–Ω—É—Ç–Ω–æ–π —Å–µ—Å—Å–∏–∏. 
                  
–ó–∞–¥–∞—á–∞:
1. –ö—Ä–∞—Ç–∫–æ –ø–æ–¥–≤–µ–¥–∏ –∏—Ç–æ–≥–∏: —á—Ç–æ –º—ã –æ–±—Å—É–¥–∏–ª–∏, –∫–∞–∫–∏–µ –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤—Å–ø–ª—ã–ª–∏
2. –û—Ç–º–µ—Ç—å, —á—Ç–æ –≤–∞–∂–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Å–µ–±—è –ø–æ–Ω—è–ª –∏–ª–∏ –æ—Å–æ–∑–Ω–∞–ª
3. –ü—Ä–µ–¥–ª–æ–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ç–µ–º—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –≤—Å—Ç—Ä–µ—á–∏, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ —Ç–æ–º, —á—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–¥–æ–æ–±—Å—É–∂–¥–µ–Ω–Ω—ã–º –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–π –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏

–ì–æ–≤–æ—Ä–∏ –æ—Ç –ø–µ—Ä–≤–æ–≥–æ –ª–∏—Ü–∞, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ –ø–æ-—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏. –ú–∞–∫—Å–∏–º—É–º —Ç—Ä–∏-—á–µ—Ç—ã—Ä–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.`;

                  const conversationForSummary = [
                    ...conversationRef.current,
                    { role: "user" as const, content: summaryPrompt }
                  ];
                  
                  const summaryResponse = await psychologistAI.getVoiceResponse(
                    conversationForSummary, 
                    memoryRef.current, 
                    false
                  );
                  
                  conversationRef.current.push({ role: "assistant", content: summaryResponse });
                  await enqueueSpeechPlayback(summaryResponse);
                  
                } catch (error) {
                  console.error("Error generating session summary:", error);
                  const fallbackMessage = "–£ –Ω–∞—Å –æ—Å—Ç–∞–ª–æ—Å—å –æ–∫–æ–ª–æ –ø—è—Ç–∏ –º–∏–Ω—É—Ç. –î–∞–≤–∞–π—Ç–µ –∫–æ—Ä–æ—Ç–∫–æ –ø–æ–¥–≤–µ–¥–µ–º –∏—Ç–æ–≥–∏ –Ω–∞—à–µ–π –±–µ—Å–µ–¥—ã –∏ —è –ø—Ä–µ–¥–ª–æ–∂—É —Ç–µ–º—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –≤—Å—Ç—Ä–µ—á–∏";
                  conversationRef.current.push({ role: "assistant", content: fallbackMessage });
                  await enqueueSpeechPlayback(fallbackMessage);
                } finally {
                  setTranscriptionStatus("");
                }
              });
          }
          
          if (next >= SESSION_DURATION_SECONDS && !callLimitReachedRef.current) {
            callLimitReachedRef.current = true;
            window.setTimeout(() => {
              setAudioError("–°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –ø—Ä–æ—à–ª–æ 30 –º–∏–Ω—É—Ç. –°–ø–∞—Å–∏–±–æ –∑–∞ –¥–æ–≤–µ—Ä–∏–µ!");
              endCall(next).catch((error) => console.error("Error auto-ending call", error));
            }, 0);
            return SESSION_DURATION_SECONDS;
          }
          
          if (next >= MAX_CALL_DURATION_SECONDS) {
            return MAX_CALL_DURATION_SECONDS;
          }
          
          return next;
        });
      }, 1000);

      setTranscriptionStatus("");
      setIsCallActive(true);
    } catch (error) {
      console.error("Error starting call:", error);
      setAudioError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.");
      cleanupRecording();
      setCurrentCallId(null);
    }
  };

  const endCall = async (overrideDuration?: number) => {
    if (!currentCallId) {
      return;
    }

    try {
      cleanupRecording();
      stopProcessingSound();

      if (callTimerRef.current) {
        clearInterval(callTimerRef.current);
        callTimerRef.current = null;
      }

      const durationToSave = overrideDuration ?? callDuration;
      console.log(`[AudioCall] Ending call ${currentCallId} with duration ${durationToSave} seconds`);

      const cleanDuration = typeof durationToSave === 'number' ? durationToSave : Number(durationToSave) || 0;
      console.log(`[AudioCall] Using clean duration: ${cleanDuration}`);

      await audioCallApi.endAudioCall(currentCallId, cleanDuration);

      if (user && durationToSave > 0 && subscriptionInfo?.plan === 'premium' && subscriptionInfo.status === 'active') {
        const result = await subscriptionApi.recordAudioSession(user.id);
        if (!result.success && result.message) {
          setAudioError(result.message);
        }
        const latestInfo = await subscriptionApi.getAudioSessionInfo(user.id);
        setSubscriptionInfo(latestInfo);
      }
    } catch (error) {
      console.error("Error ending call:", error);
      setAudioError("–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –∑–≤–æ–Ω–æ–∫.");
    } finally {
      stopAssistantSpeech();
      pauseBackgroundMusic(); // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –º—É–∑—ã–∫—É
      setIsMusicOn(false); // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º—É–∑—ã–∫–∏
      pauseVideo(); // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∏–¥–µ–æ
      setIsVideoPlaying(false); // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–∏–¥–µ–æ
      setIsCallActive(false);
      setCallDuration(0);
      setIsMuted(false);
      isMutedRef.current = false;
      setCurrentCallId(null);
      setTranscriptionStatus(null);
      callLimitReachedRef.current = false;
      callLimitWarningSentRef.current = false;
      memoryRef.current = "";

      if (audioStreamRef.current) {
        audioStreamRef.current = null;
      }
      if (audioContextRef.current) {
        audioContextRef.current = null;
      }
    }
  };

  const formatDuration = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  };

  return (
    <div className="min-h-screen bg-calm-gradient">
      <Navigation />
      
      <div className="pt-24 pb-8 px-4">
        <div className="container mx-auto max-w-2xl">
          <div className="text-center mb-8 animate-fade-in">
            <h1 className="text-4xl font-bold text-foreground mb-3">–ê—É–¥–∏–æ –∑–≤–æ–Ω–æ–∫</h1>
            <p className="text-muted-foreground">–ì–æ–ª–æ—Å–æ–≤–∞—è —Å–µ—Å—Å–∏—è —Å –ò–ò-–ø—Å–∏—Ö–æ–ª–æ–≥–æ–º</p>
          </div>

          <Card className="bg-card-gradient border-2 border-border shadow-strong p-8 md:p-12 text-center animate-scale-in">
            {!isCallActive ? (
              <div className="space-y-8">
                <div className="w-[180px] h-[180px] sm:w-[260px] sm:h-[260px] md:w-[320px] md:h-[320px] mx-auto rounded-full overflow-hidden shadow-strong">
                  <video
                    ref={videoRef}
                    src="/Untitled Video.mp4"
                    className="w-full h-full object-cover pointer-events-none"
                    style={{
                      transform: 'translateX(5px) scale(1.05)',
                      objectPosition: '50% 50%'
                    }}
                    muted
                    playsInline
                  />
                </div>
                
                <div>
                  <h2 className="text-2xl font-bold text-foreground mb-2">
                    –ù–∞—á–∞—Ç—å –∑–≤–æ–Ω–æ–∫ —Å –ø—Å–∏—Ö–æ–ª–æ–≥–æ–º
                  </h2>
                  <p className="text-muted-foreground">
                    –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—É—é —Å–µ—Å—Å–∏—é
                  </p>
                  {subscriptionInfo && subscriptionInfo.plan === 'premium' ? (
                    <p className="mt-3 text-sm text-primary font-medium">
                      –û—Å—Ç–∞–ª–æ—Å—å –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–π: {subscriptionInfo.remaining} –∏–∑ {subscriptionInfo.limit}
                    </p>
                  ) : subscriptionInfo ? (
                    <p className="mt-3 text-sm text-muted-foreground">
                      –û—Å—Ç–∞–ª–æ—Å—å –∞—É–¥–∏–æ —Å–µ—Å—Å–∏–π: {subscriptionInfo.remaining} –∏–∑ {subscriptionInfo.limit}
                    </p>
                  ) : null}
                </div>

                <Button
                  onClick={startCall}
                  size="lg"
                  className="bg-hero-gradient text-white hover:shadow-lg  shadow-medium text-lg px-12 py-6"
                  disabled={loading}
                >
                  <Phone className="w-6 h-6 mr-2" />
                  {loading ? "–ó–∞–≥—Ä—É–∑–∫–∞..." : "–ü–æ–∑–≤–æ–Ω–∏—Ç—å"}
                </Button>

                <div className="pt-8 border-t border-border">
                  <h3 className="text-lg font-semibold text-foreground mb-4">–°–æ–≤–µ—Ç—ã –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–≥–æ –∑–≤–æ–Ω–∫–∞:</h3>
                  <ul className="text-left text-muted-foreground space-y-2 max-w-md mx-auto">
                    <li>‚Ä¢ –ù–∞–π–¥–∏—Ç–µ —Ç–∏—Ö–æ–µ –º–µ—Å—Ç–æ, –≥–¥–µ –≤–∞—Å –Ω–∏–∫—Ç–æ –Ω–µ –ø–æ–±–µ—Å–ø–æ–∫–æ–∏—Ç</li>
                    <li>‚Ä¢ –ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç–∏—Ç–µ –æ–±—Å—É–¥–∏—Ç—å</li>
                    <li>‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ –æ—Ç–∫—Ä—ã—Ç–æ –∏ —á–µ—Å—Ç–Ω–æ</li>
                    <li>‚Ä¢ –ù–µ —Ç–æ—Ä–æ–ø–∏—Ç–µ—Å—å, –¥–∞–π—Ç–µ —Å–µ–±–µ –≤—Ä–µ–º—è –ø–æ–¥—É–º–∞—Ç—å</li>
                  </ul>
                </div>
              </div>
            ) : (
              <div className="space-y-8">
                <div className="w-[220px] h-[220px] sm:w-[320px] sm:h-[320px] md:w-[400px] md:h-[400px] mx-auto rounded-full overflow-hidden shadow-strong">
                  <video
                    ref={videoRef}
                    src="/Untitled Video.mp4"
                    className="w-full h-full object-cover pointer-events-none"
                    style={{
                      transform: 'translateX(5px) scale(1.05)',
                      objectPosition: '50% 50%'
                    }}
                    muted
                    playsInline
                  />
                </div>

                <div>
                  <h2 className="text-2xl font-bold text-foreground mb-2">
                    –ó–≤–æ–Ω–æ–∫ –∏–¥–µ—Ç
                  </h2>
                  <div className="text-center mt-4">
                    <div className="text-lg font-medium text-primary">
                      {formatDuration(callDuration)}
                    </div>
                    {callDuration >= SESSION_WARNING_SECONDS && callDuration < SESSION_DURATION_SECONDS && (
                      <div className="mt-2 text-sm text-orange-500 animate-pulse font-medium">
                        –û—Å—Ç–∞–ª–æ—Å—å ~{Math.ceil((SESSION_DURATION_SECONDS - callDuration) / 60)} –º–∏–Ω—É—Ç
                      </div>
                    )}
                    <div className="mt-3 w-48 mx-auto h-1.5 bg-gray-200 rounded-full overflow-hidden">
                      <div 
                        className={`h-full transition-all duration-1000 ${callDuration >= SESSION_WARNING_SECONDS
                            ? 'bg-orange-500' 
                            : 'bg-blue-500'
                        }`}
                        style={{ width: `${Math.min((callDuration / SESSION_DURATION_SECONDS) * 100, 100)}%` }}
                      />
                    </div>
                  </div>
                </div>

                <div className="flex justify-center gap-4">
                  <Button
                    onClick={() => setIsMuted(!isMuted)}
                    size="lg"
                    variant={isMuted ? "destructive" : "outline"}
                    className="rounded-full w-16 h-16 p-0"
                  >
                    {isMuted ? <MicOff className="w-6 h-6" /> : <Mic className="w-6 h-6" />}
                  </Button>

                  <Button
                    onClick={() => setIsSpeakerOn(!isSpeakerOn)}
                    size="lg"
                    variant={!isSpeakerOn ? "destructive" : "outline"}
                    className="rounded-full w-16 h-16 p-0"
                  >
                    {isSpeakerOn ? <Volume2 className="w-6 h-6" /> : <VolumeX className="w-6 h-6" />}
                  </Button>

                  <Button
                    onClick={toggleBackgroundMusic}
                    size="lg"
                    variant={isMusicOn ? "default" : "outline"}
                    className="rounded-full w-16 h-16 p-0"
                    title={isMusicOn ? "–í—ã–∫–ª—é—á–∏—Ç—å —Ñ–æ–Ω–æ–≤—É—é –º—É–∑—ã–∫—É" : "–í–∫–ª—é—á–∏—Ç—å —Ñ–æ–Ω–æ–≤—É—é –º—É–∑—ã–∫—É"}
                  >
                    {isMusicOn ? <Music className="w-6 h-6" /> : <Music className="w-6 h-6 opacity-40" />}
                  </Button>

                  <Button
                    onClick={() => endCall()}
                    size="lg"
                    variant="destructive"
                    className="rounded-full w-16 h-16 p-0 shadow-medium"
                  >
                    <PhoneOff className="w-6 h-6" />
                  </Button>
                </div>

                <div className="text-center text-sm text-muted-foreground">
                  {!isSpeakerOn && <p>–ó–≤—É–∫ –≤—ã–∫–ª—é—á–µ–Ω</p>}
                  {isMusicOn && <p className="text-green-500 font-medium">üéµ –§–æ–Ω–æ–≤–∞—è –º—É–∑—ã–∫–∞ –∏–≥—Ä–∞–µ—Ç</p>}
                </div>

                {subscriptionInfo && (
                  <p className="text-xs text-muted-foreground">
                    –û—Å—Ç–∞–ª–æ—Å—å —Å–µ—Å—Å–∏–π –≤ —ç—Ç–æ–º –º–µ—Å—è—Ü–µ: {subscriptionInfo.remaining} –∏–∑ {subscriptionInfo.limit}
                  </p>
                )}

                {transcriptionStatus && (
                  <div className="flex items-center gap-2">
                    <p className="text-sm text-primary/80">{transcriptionStatus}</p>
                    {transcriptionStatus.includes("–æ–±–¥—É–º—ã–≤–∞–µ—Ç") && (
                      <Button
                        onClick={() => {
                          // –ü—Ä–µ—Ä—ã–≤–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ –∏ –æ—á–∏—â–∞–µ–º —Å—Ç–∞—Ç—É—Å
                          if (pendingProcessTimeoutRef.current) {
                            window.clearTimeout(pendingProcessTimeoutRef.current);
                            pendingProcessTimeoutRef.current = null;
                          }
                          setTranscriptionStatus("");
                          console.log("[AudioCall] User skipped waiting for response");
                        }}
                        size="sm"
                        variant="outline"
                        className="text-xs px-2 py-1"
                      >
                        –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å
                      </Button>
                    )}
                  </div>
                )}

                {audioError && (
                  <p className="text-sm text-destructive">{audioError}</p>
                )}
              </div>
            )}
          </Card>
        </div>
      </div>
    </div>
  );
};

export default AudioCall;
